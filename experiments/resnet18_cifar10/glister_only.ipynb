{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Combining Coords and Composer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc058b9be2bb4b858e68123d409fe946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe81aadffb00465b88d39aa5af637f54",
              "IPY_MODEL_bf8b14d4d6974f588572ab91be0589d4",
              "IPY_MODEL_186caf0425a54e6c82c270725da61008"
            ],
            "layout": "IPY_MODEL_c698abdeb6394d6e8f997049aeb15909"
          }
        },
        "fe81aadffb00465b88d39aa5af637f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a9a166f5a064ea282ce6c0d2f51acac",
            "placeholder": "​",
            "style": "IPY_MODEL_4675411331ac4f02afec7d8f3114295c",
            "value": ""
          }
        },
        "bf8b14d4d6974f588572ab91be0589d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62783e7c027847e3b28a2d0639363171",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37db6189be73470b9eb49e91eb144d63",
            "value": 170498071
          }
        },
        "186caf0425a54e6c82c270725da61008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87e4a7b7ada74b30ab28a989bbc6413c",
            "placeholder": "​",
            "style": "IPY_MODEL_d851581df9ae4e6089901cfc5acceb5d",
            "value": " 170499072/? [00:06&lt;00:00, 29454064.96it/s]"
          }
        },
        "c698abdeb6394d6e8f997049aeb15909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a9a166f5a064ea282ce6c0d2f51acac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4675411331ac4f02afec7d8f3114295c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62783e7c027847e3b28a2d0639363171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37db6189be73470b9eb49e91eb144d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87e4a7b7ada74b30ab28a989bbc6413c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d851581df9ae4e6089901cfc5acceb5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaviShah1/Combining-Cords-and-Compose/blob/main/experiments/resnet18_cifar10/glister_only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/decile-team/cords.git\n",
        "%cd cords\n",
        "%ls"
      ],
      "metadata": {
        "id": "pJewp117QDUI",
        "outputId": "13e92d85-64e3-4bce-9f0d-95b7244f9660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cords'...\n",
            "remote: Enumerating objects: 4718, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 4718 (delta 12), reused 10 (delta 4), pack-reused 4685\u001b[K\n",
            "Receiving objects: 100% (4718/4718), 58.35 MiB | 18.40 MiB/s, done.\n",
            "Resolving deltas: 100% (2864/2864), done.\n",
            "/content/cords\n",
            "\u001b[0m\u001b[01;34mbenchmarks\u001b[0m/   \u001b[01;34mcords\u001b[0m/     LICENSE.txt    setup.py      train_sl.py\n",
            "CITATION.CFF  \u001b[01;34mdocs\u001b[0m/      README.md      \u001b[01;34mtests\u001b[0m/        train_ssl.py\n",
            "\u001b[01;34mconfigs\u001b[0m/      \u001b[01;34mexamples\u001b[0m/  \u001b[01;34mrequirements\u001b[0m/  train_hpo.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dotmap apricot-select ray[default] ray[tune] mosaicml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "37QszJkXYAZz",
        "outputId": "7788a9af-262c-4617-9935-2e0ff1a239ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dotmap\n",
            "  Downloading dotmap-1.3.30-py3-none-any.whl (11 kB)\n",
            "Collecting apricot-select\n",
            "  Downloading apricot-select-0.6.1.tar.gz (28 kB)\n",
            "Collecting ray[default]\n",
            "  Downloading ray-1.13.0-cp37-cp37m-manylinux2014_x86_64.whl (54.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.5 MB 182 kB/s \n",
            "\u001b[?25hCollecting mosaicml\n",
            "  Downloading mosaicml-0.8.0-py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (0.51.2)\n",
            "Requirement already satisfied: tqdm>=4.24.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (4.64.0)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 70.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->apricot-select) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->apricot-select) (0.34.0)\n",
            "Requirement already satisfied: torch<2,>=1.9 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (1.11.0+cu113)\n",
            "Collecting requests<3,>=2.26.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting torchmetrics<0.8,>=0.7.0\n",
            "  Downloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n",
            "\u001b[K     |████████████████████████████████| 398 kB 59.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (0.12.0+cu113)\n",
            "Collecting psutil<6,>=5.8.0\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 72.0 MB/s \n",
            "\u001b[?25hCollecting yahp<0.2,>=0.1.1\n",
            "  Downloading yahp-0.1.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=8.0.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 834 kB/s \n",
            "\u001b[?25hCollecting pyyaml<7,>=6.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 65.2 MB/s \n",
            "\u001b[?25hCollecting torch-optimizer<0.2,>=0.1.0\n",
            "  Downloading torch_optimizer-0.1.0-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting coolname<2,>=1.1.0\n",
            "  Downloading coolname-1.1.0-py2.py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.26.0->mosaicml) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.26.0->mosaicml) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.26.0->mosaicml) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.26.0->mosaicml) (2.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.9->mosaicml) (4.1.1)\n",
            "Collecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Collecting pyDeprecate==0.3.*\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics<0.8,>=0.7.0->mosaicml) (21.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.10.0->mosaicml) (7.1.2)\n",
            "Collecting ruamel.yaml>=0.17.10\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 73.3 MB/s \n",
            "\u001b[?25hCollecting docstring-parser<=0.15,>=0.14.1\n",
            "  Downloading docstring_parser-0.14.1-py3-none-any.whl (33 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 73.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics<0.8,>=0.7.0->mosaicml) (3.0.9)\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.15.1-py2.py3-none-any.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 52.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.0.4)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.7.1)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (7.1.2)\n",
            "Collecting frozenlist\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 75.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[default]) (21.4.0)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 53.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]) (4.3.3)\n",
            "Collecting aiosignal\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting opencensus\n",
            "  Downloading opencensus-0.9.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 77.1 MB/s \n",
            "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
            "  Downloading gpustat-1.0.0rc1.tar.gz (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 10.8 MB/s \n",
            "\u001b[?25hCollecting colorful\n",
            "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[K     |████████████████████████████████| 201 kB 66.7 MB/s \n",
            "\u001b[?25hCollecting prometheus-client<0.14.0,>=0.7.1\n",
            "  Downloading prometheus_client-0.13.1-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting aiohttp>=3.7\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 66.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]) (5.2.1)\n",
            "Collecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.12-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 58.5 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 77.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]) (1.15.0)\n",
            "Collecting nvidia-ml-py<=11.495.46,>=11.450.129\n",
            "  Downloading nvidia_ml_py-11.495.46-py3-none-any.whl (25 kB)\n",
            "Collecting blessed>=1.17.1\n",
            "  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[default]) (0.2.5)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]) (5.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]) (4.11.4)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray[default]) (3.8.0)\n",
            "Collecting opencensus-context>=0.1.2\n",
            "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]) (1.31.6)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (1.35.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (2022.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (1.56.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (4.2.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (0.4.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.3.5)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 75.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.8.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[default]) (2.8.2)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 68.0 MB/s \n",
            "\u001b[?25hCollecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: apricot-select, py-cpuinfo, gpustat\n",
            "  Building wheel for apricot-select (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apricot-select: filename=apricot_select-0.6.1-py3-none-any.whl size=48786 sha256=09894f835808062245652540eb4f89a4c16930634d62a449a0d1c56b6509d38f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/b0/5d/41bab30f23d17864700963dad70bbeda159a409e94f0778f2f\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=365969bb080ab98c0e5b9fc2192c4dc8f7f6654b59cbfd9076c2ca4f235010c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.0.0rc1-py3-none-any.whl size=18872 sha256=b4a0f674d3d67bb85d90143033c2332cf5c384a315b1312d846519b325640504\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/85/03/7f87ed3a11307c5ad083829b59731788971a8411c265984409\n",
            "Successfully built apricot-select py-cpuinfo gpustat\n",
            "Installing collected packages: multidict, frozenlist, yarl, ruamel.yaml.clib, requests, platformdirs, distlib, asynctest, async-timeout, aiosignal, virtualenv, ruamel.yaml, pyyaml, pytorch-ranger, pyDeprecate, psutil, opencensus-context, nvidia-ml-py, grpcio, docstring-parser, blessed, aiohttp, yahp, torchmetrics, torch-optimizer, tensorboardX, ray, py-spy, py-cpuinfo, prometheus-client, opencensus, nose, gpustat, coolname, colorful, aiohttp-cors, mosaicml, dotmap, apricot-select\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.3\n",
            "    Uninstalling grpcio-1.46.3:\n",
            "      Successfully uninstalled grpcio-1.46.3\n",
            "  Attempting uninstall: prometheus-client\n",
            "    Found existing installation: prometheus-client 0.14.1\n",
            "    Uninstalling prometheus-client-0.14.1:\n",
            "      Successfully uninstalled prometheus-client-0.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiohttp-cors-0.7.0 aiosignal-1.2.0 apricot-select-0.6.1 async-timeout-4.0.2 asynctest-0.13.0 blessed-1.19.1 colorful-0.5.4 coolname-1.1.0 distlib-0.3.4 docstring-parser-0.14.1 dotmap-1.3.30 frozenlist-1.3.0 gpustat-1.0.0rc1 grpcio-1.43.0 mosaicml-0.8.0 multidict-6.0.2 nose-1.3.7 nvidia-ml-py-11.495.46 opencensus-0.9.0 opencensus-context-0.1.2 platformdirs-2.5.2 prometheus-client-0.13.1 psutil-5.9.1 py-cpuinfo-8.0.0 py-spy-0.3.12 pyDeprecate-0.3.2 pytorch-ranger-0.1.1 pyyaml-6.0 ray-1.13.0 requests-2.28.1 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 tensorboardX-2.5.1 torch-optimizer-0.1.0 torchmetrics-0.7.3 virtualenv-20.15.1 yahp-0.1.1 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from cords.utils.data.datasets.SL import gen_dataset\n",
        "from torch.utils.data import Subset\n",
        "from cords.utils.config_utils import load_config_data\n",
        "import os.path as osp\n",
        "from cords.utils.data.data_utils import WeightedSubset\n",
        "from composer import functional as cf\n",
        "from ray import tune"
      ],
      "metadata": {
        "id": "IFtimJsDYBSm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, validset, testset, num_cls = gen_dataset('data/', 'cifar10', None, isnumpy=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "dc058b9be2bb4b858e68123d409fe946",
            "fe81aadffb00465b88d39aa5af637f54",
            "bf8b14d4d6974f588572ab91be0589d4",
            "186caf0425a54e6c82c270725da61008",
            "c698abdeb6394d6e8f997049aeb15909",
            "0a9a166f5a064ea282ce6c0d2f51acac",
            "4675411331ac4f02afec7d8f3114295c",
            "62783e7c027847e3b28a2d0639363171",
            "37db6189be73470b9eb49e91eb144d63",
            "87e4a7b7ada74b30ab28a989bbc6413c",
            "d851581df9ae4e6089901cfc5acceb5d"
          ]
        },
        "id": "fCOZOz0CYDmA",
        "outputId": "21f48ddc-5769-42fb-d991-77ee4f814902"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc058b9be2bb4b858e68123d409fe946"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trn_batch_size = 20\n",
        "val_batch_size = 20\n",
        "tst_batch_size = 1000\n",
        "\n",
        "# Creating the Data Loaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=trn_batch_size,\n",
        "                                          shuffle=False, pin_memory=True)\n",
        "\n",
        "valloader = torch.utils.data.DataLoader(validset, batch_size=val_batch_size,\n",
        "                                        shuffle=False, pin_memory=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=tst_batch_size,\n",
        "                                          shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "JJji-yh0YIEY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cords.utils.models import ResNet18\n",
        "numclasses = 10\n",
        "device = 'cuda' #Device Argument\n",
        "model = ResNet18(10)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "6Qj5KIyEYJ8M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion_nored = nn.CrossEntropyLoss(reduction='none')"
      ],
      "metadata": {
        "id": "8Tvpow1wYLWZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_ckpt(state, ckpt_path):\n",
        "    torch.save(state, ckpt_path)\n",
        "\n",
        "\n",
        "def load_ckpt(ckpt_path, model, optimizer):\n",
        "    checkpoint = torch.load(ckpt_path)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    loss = checkpoint['loss']\n",
        "    metrics = checkpoint['metrics']\n",
        "    return start_epoch, model, optimizer, loss, metrics"
      ],
      "metadata": {
        "id": "uJhZ8d3vYNBh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_cumulative_timing(mod_timing):\n",
        "    tmp = 0\n",
        "    mod_cum_timing = np.zeros(len(mod_timing))\n",
        "    for i in range(len(mod_timing)):\n",
        "        tmp += mod_timing[i]\n",
        "        mod_cum_timing[i] = tmp\n",
        "    return mod_cum_timing / 3600"
      ],
      "metadata": {
        "id": "0hx_sinTYOdX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=1e-2,\n",
        "                                  momentum=0.9,\n",
        "                                  weight_decay=5e-4,\n",
        "                                  nesterov=False)\n",
        "\n",
        "#T_max is the maximum number of scheduler steps. Here we are using the number of epochs as the maximum number of scheduler steps.\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "                                                       T_max=30)"
      ],
      "metadata": {
        "id": "kLHSf3WEYP3_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __get_logger(results_dir):\n",
        "  os.makedirs(results_dir, exist_ok=True)\n",
        "  # setup logger\n",
        "  plain_formatter = logging.Formatter(\"[%(asctime)s] %(name)s %(levelname)s: %(message)s\",\n",
        "                                      datefmt=\"%m/%d %H:%M:%S\")\n",
        "  logger = logging.getLogger(__name__)\n",
        "  logger.setLevel(logging.INFO)\n",
        "  s_handler = logging.StreamHandler(stream=sys.stdout)\n",
        "  s_handler.setFormatter(plain_formatter)\n",
        "  s_handler.setLevel(logging.INFO)\n",
        "  logger.addHandler(s_handler)\n",
        "  f_handler = logging.FileHandler(os.path.join(results_dir, \"results.log\"))\n",
        "  f_handler.setFormatter(plain_formatter)\n",
        "  f_handler.setLevel(logging.DEBUG)\n",
        "  logger.addHandler(f_handler)\n",
        "  logger.propagate = False\n",
        "  return logger"
      ],
      "metadata": {
        "id": "wAopp5oFYRJJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import os.path as osp\n",
        "import sys\n",
        "\n",
        "#Results logging directory\n",
        "results_dir = osp.abspath(osp.expanduser('results'))\n",
        "logger = __get_logger(results_dir)"
      ],
      "metadata": {
        "id": "6AQkQW5XYSqA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info(\"hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAh0aXRKYWzi",
        "outputId": "429b2861-da9a-4970-9c6c-c43f4241a0b6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07/05 06:58:44] __main__ INFO: hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cords.utils.data.dataloader.SL.adaptive import GLISTERDataLoader, OLRandomDataLoader, \\\n",
        "    CRAIGDataLoader, GradMatchDataLoader, RandomDataLoader\n",
        "from dotmap import DotMap\n",
        "\n",
        "selection_strategy = 'GLISTER'\n",
        "dss_args = dict(model=model,\n",
        "                loss=criterion_nored,\n",
        "                eta=0.01,\n",
        "                num_classes=10,\n",
        "                num_epochs=30,\n",
        "                device='cuda',\n",
        "                fraction=0.1,\n",
        "                select_every=10,\n",
        "                kappa=0,\n",
        "                linear_layer=False,\n",
        "                selection_type='SL',\n",
        "                greedy='Stochastic')\n",
        "dss_args = DotMap(dss_args)\n",
        "\n",
        "dataloader = GLISTERDataLoader(trainloader, valloader, dss_args, logger, \n",
        "                                  batch_size=20, \n",
        "                                  shuffle=True,\n",
        "                                  pin_memory=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P72TwdhcYYL8",
        "outputId": "4578590a-3ecd-4430-c5ba-c4dccf79ed81"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\u001b[0m\n",
            "  warnings.warn(problem)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Arguments\n",
        "num_epochs = 30\n",
        "\n",
        "#Arguments for results logging\n",
        "print_every = 1\n",
        "print_args = [\"val_loss\", \"val_acc\", \"tst_loss\", \"tst_acc\", \"time\"]\n",
        "\n",
        "#Argumets for checkpointing\n",
        "save_every = 20\n",
        "is_save = True\n",
        "\n",
        "#Evaluation Metrics\n",
        "trn_losses = list()\n",
        "val_losses = list()\n",
        "tst_losses = list()\n",
        "subtrn_losses = list()\n",
        "timing = list()\n",
        "trn_acc = list()\n",
        "val_acc = list()  \n",
        "tst_acc = list()  \n",
        "subtrn_acc = list()"
      ],
      "metadata": {
        "id": "hN182L3MYa8a"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "################################################# Training Loop #################################################\n",
        "\"\"\"\n",
        "for epoch in range(num_epochs):\n",
        "    subtrn_loss = 0\n",
        "    subtrn_correct = 0\n",
        "    subtrn_total = 0\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    for _, (inputs, targets, weights) in enumerate(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "        weights = weights.to(device)  \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        losses = criterion_nored(outputs, targets)\n",
        "        loss = torch.dot(losses, weights/(weights.sum()))\n",
        "        loss.backward()\n",
        "        subtrn_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        _, predicted = outputs.max(1)\n",
        "        subtrn_total += targets.size(0)\n",
        "        subtrn_correct += predicted.eq(targets).sum().item()\n",
        "    epoch_time = time.time() - start_time\n",
        "    scheduler.step()\n",
        "    timing.append(epoch_time)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    ################################################# Evaluation Loop #################################################\n",
        "    \"\"\"\n",
        "\n",
        "    if (epoch + 1) % print_every == 0:\n",
        "        trn_loss = 0\n",
        "        trn_correct = 0\n",
        "        trn_total = 0\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        tst_correct = 0\n",
        "        tst_total = 0\n",
        "        tst_loss = 0\n",
        "        model.eval()\n",
        "\n",
        "        if (\"trn_loss\" in print_args) or (\"trn_acc\" in print_args):\n",
        "            with torch.no_grad():\n",
        "                for _, (inputs, targets) in enumerate(trainloader):\n",
        "                    inputs, targets = inputs.to(device), \\\n",
        "                                      targets.to(device, non_blocking=True)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    trn_loss += loss.item()\n",
        "                    if \"trn_acc\" in print_args:\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        trn_total += targets.size(0)\n",
        "                        trn_correct += predicted.eq(targets).sum().item()\n",
        "                trn_losses.append(trn_loss)\n",
        "\n",
        "            if \"trn_acc\" in print_args:\n",
        "                trn_acc.append(trn_correct / trn_total)\n",
        "\n",
        "        if (\"val_loss\" in print_args) or (\"val_acc\" in print_args):\n",
        "            with torch.no_grad():\n",
        "                for _, (inputs, targets) in enumerate(valloader):\n",
        "                    inputs, targets = inputs.to(device), \\\n",
        "                                      targets.to(device, non_blocking=True)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    val_loss += loss.item()\n",
        "                    if \"val_acc\" in print_args:\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        val_total += targets.size(0)\n",
        "                        val_correct += predicted.eq(targets).sum().item()\n",
        "                val_losses.append(val_loss)\n",
        "\n",
        "            if \"val_acc\" in print_args:\n",
        "                val_acc.append(val_correct / val_total)\n",
        "\n",
        "        if (\"tst_loss\" in print_args) or (\"tst_acc\" in print_args):\n",
        "            with torch.no_grad():\n",
        "                for _, (inputs, targets) in enumerate(testloader):\n",
        "                    inputs, targets = inputs.to(device), \\\n",
        "                                      targets.to(device, non_blocking=True)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    tst_loss += loss.item()\n",
        "                    if \"tst_acc\" in print_args:\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        tst_total += targets.size(0)\n",
        "                        tst_correct += predicted.eq(targets).sum().item()\n",
        "                tst_losses.append(tst_loss)\n",
        "\n",
        "            if \"tst_acc\" in print_args:\n",
        "                tst_acc.append(tst_correct / tst_total)\n",
        "\n",
        "        if \"subtrn_acc\" in print_args:\n",
        "            subtrn_acc.append(subtrn_correct / subtrn_total)\n",
        "\n",
        "        if \"subtrn_losses\" in print_args:\n",
        "            subtrn_losses.append(subtrn_loss)\n",
        "\n",
        "        print_str = \"Epoch: \" + str(epoch + 1)\n",
        "\n",
        "        \"\"\"\n",
        "        ################################################# Results Printing #################################################\n",
        "        \"\"\"\n",
        "\n",
        "        for arg in print_args:\n",
        "\n",
        "            if arg == \"val_loss\":\n",
        "                print_str += \" , \" + \"Validation Loss: \" + str(val_losses[-1])\n",
        "\n",
        "            if arg == \"val_acc\":\n",
        "                print_str += \" , \" + \"Validation Accuracy: \" + str(val_acc[-1])\n",
        "\n",
        "            if arg == \"tst_loss\":\n",
        "                print_str += \" , \" + \"Test Loss: \" + str(tst_losses[-1])\n",
        "\n",
        "            if arg == \"tst_acc\":\n",
        "                print_str += \" , \" + \"Test Accuracy: \" + str(tst_acc[-1])\n",
        "\n",
        "            if arg == \"trn_loss\":\n",
        "                print_str += \" , \" + \"Training Loss: \" + str(trn_losses[-1])\n",
        "\n",
        "            if arg == \"trn_acc\":\n",
        "                print_str += \" , \" + \"Training Accuracy: \" + str(trn_acc[-1])\n",
        "\n",
        "            if arg == \"subtrn_loss\":\n",
        "                print_str += \" , \" + \"Subset Loss: \" + str(subtrn_losses[-1])\n",
        "\n",
        "            if arg == \"subtrn_acc\":\n",
        "                print_str += \" , \" + \"Subset Accuracy: \" + str(subtrn_acc[-1])\n",
        "\n",
        "            if arg == \"time\":\n",
        "                print_str += \" , \" + \"Timing: \" + str(timing[-1])\n",
        "\n",
        "        logger.info(print_str)\n",
        "\n",
        "    \"\"\"\n",
        "    ################################################# Checkpoint Saving #################################################\n",
        "    \"\"\"\n",
        "\n",
        "    if ((epoch + 1) % save_every == 0) and is_save:\n",
        "\n",
        "        metric_dict = {}\n",
        "\n",
        "        for arg in print_args:\n",
        "            if arg == \"val_loss\":\n",
        "                metric_dict['val_loss'] = val_losses\n",
        "            if arg == \"val_acc\":\n",
        "                metric_dict['val_acc'] = val_acc\n",
        "            if arg == \"tst_loss\":\n",
        "                metric_dict['tst_loss'] = tst_losses\n",
        "            if arg == \"tst_acc\":\n",
        "                metric_dict['tst_acc'] = tst_acc\n",
        "            if arg == \"trn_loss\":\n",
        "                metric_dict['trn_loss'] = trn_losses\n",
        "            if arg == \"trn_acc\":\n",
        "                metric_dict['trn_acc'] = trn_acc\n",
        "            if arg == \"subtrn_loss\":\n",
        "                metric_dict['subtrn_loss'] = subtrn_losses\n",
        "            if arg == \"subtrn_acc\":\n",
        "                metric_dict['subtrn_acc'] = subtrn_acc\n",
        "            if arg == \"time\":\n",
        "                metric_dict['time'] = timing\n",
        "\n",
        "        ckpt_state = {\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'loss': criterion_nored,\n",
        "            'metrics': metric_dict\n",
        "        }\n",
        "\n",
        "        # save checkpoint\n",
        "        save_ckpt(ckpt_state, 'model.pt')\n",
        "        logger.info(\"Model checkpoint saved at epoch: {0:d}\".format(epoch + 1))\n",
        "\n",
        "\"\"\"\n",
        "################################################# Results Summary #################################################\n",
        "\"\"\"\n",
        "\n",
        "logger.info(\"{0:s} Selection Run---------------------------------\".format(selection_strategy))\n",
        "logger.info(\"Final SubsetTrn: {0:f}\".format(subtrn_loss))\n",
        "if \"val_loss\" in print_args:\n",
        "    if \"val_acc\" in print_args:\n",
        "        logger.info(\"Validation Loss: %.2f , Validation Accuracy: %.2f\", val_loss, val_acc[-1])\n",
        "    else:\n",
        "        logger.info(\"Validation Loss: %.2f\", val_loss)\n",
        "\n",
        "if \"tst_loss\" in print_args:\n",
        "    if \"tst_acc\" in print_args:\n",
        "        logger.info(\"Test Loss: %.2f, Test Accuracy: %.2f\", tst_loss, tst_acc[-1])\n",
        "    else:\n",
        "        logger.info(\"Test Data Loss: %f\", tst_loss)\n",
        "logger.info('---------------------------------------------------------------------')\n",
        "logger.info(selection_strategy)\n",
        "logger.info('---------------------------------------------------------------------')\n",
        "\n",
        "\"\"\"\n",
        "################################################# Final Results Logging #################################################\n",
        "\"\"\"\n",
        "\n",
        "if \"val_acc\" in print_args:\n",
        "    val_str = \"Validation Accuracy, \"\n",
        "    for val in val_acc:\n",
        "        val_str = val_str + \" , \" + str(val)\n",
        "    logger.info(val_str)\n",
        "\n",
        "if \"tst_acc\" in print_args:\n",
        "    tst_str = \"Test Accuracy, \"\n",
        "    for tst in tst_acc:\n",
        "        tst_str = tst_str + \" , \" + str(tst)\n",
        "    logger.info(tst_str)\n",
        "\n",
        "if \"time\" in print_args:\n",
        "    time_str = \"Time, \"\n",
        "    for t in timing:\n",
        "        time_str = time_str + \" , \" + str(t)\n",
        "    logger.info(timing)\n",
        "\n",
        "timing_array = np.array(timing)\n",
        "cum_timing = list(generate_cumulative_timing(timing_array))\n",
        "logger.info(\"Total time taken by %s = %.4f \", selection_strategy, cum_timing[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "243ksusPYc59",
        "outputId": "8d4b1f11-96c9-45ff-cf70-a51a0ebf5b27"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07/05 06:59:01] __main__ INFO: Epoch: 1 , Validation Loss: 517.0257946252823 , Validation Accuracy: 0.2712 , Test Loss: 20.615378618240356 , Test Accuracy: 0.2861 , Timing: 6.719554662704468\n",
            "[07/05 06:59:14] __main__ INFO: Epoch: 2 , Validation Loss: 454.3494987487793 , Validation Accuracy: 0.3304 , Test Loss: 17.747700214385986 , Test Accuracy: 0.3377 , Timing: 6.184462308883667\n",
            "[07/05 06:59:27] __main__ INFO: Epoch: 3 , Validation Loss: 455.78947925567627 , Validation Accuracy: 0.3408 , Test Loss: 17.319190859794617 , Test Accuracy: 0.3626 , Timing: 6.232213497161865\n",
            "[07/05 06:59:39] __main__ INFO: Epoch: 4 , Validation Loss: 415.6052017211914 , Validation Accuracy: 0.3798 , Test Loss: 17.153046250343323 , Test Accuracy: 0.3771 , Timing: 6.179301738739014\n",
            "[07/05 06:59:52] __main__ INFO: Epoch: 5 , Validation Loss: 391.4489980340004 , Validation Accuracy: 0.4378 , Test Loss: 15.834443926811218 , Test Accuracy: 0.438 , Timing: 6.223090648651123\n",
            "[07/05 07:00:05] __main__ INFO: Epoch: 6 , Validation Loss: 365.7184737920761 , Validation Accuracy: 0.4544 , Test Loss: 14.567855834960938 , Test Accuracy: 0.4569 , Timing: 6.186913967132568\n",
            "[07/05 07:00:18] __main__ INFO: Epoch: 7 , Validation Loss: 375.2182695865631 , Validation Accuracy: 0.4702 , Test Loss: 14.529971837997437 , Test Accuracy: 0.485 , Timing: 6.183251857757568\n",
            "[07/05 07:00:31] __main__ INFO: Epoch: 8 , Validation Loss: 341.86251360177994 , Validation Accuracy: 0.5046 , Test Loss: 13.638545751571655 , Test Accuracy: 0.5117 , Timing: 6.198957681655884\n",
            "[07/05 07:00:44] __main__ INFO: Epoch: 9 , Validation Loss: 335.40997326374054 , Validation Accuracy: 0.523 , Test Loss: 12.985176682472229 , Test Accuracy: 0.5333 , Timing: 6.228888273239136\n",
            "[07/05 07:00:57] __main__ INFO: Epoch: 10 , Validation Loss: 314.8474845290184 , Validation Accuracy: 0.5496 , Test Loss: 12.15581488609314 , Test Accuracy: 0.5625 , Timing: 6.207472324371338\n",
            "[07/05 07:01:29] __main__ INFO: Epoch: 11, GLISTER dataloader subset selection finished, takes 32.3205. \n",
            "[07/05 07:01:42] __main__ INFO: Epoch: 11 , Validation Loss: 356.3417283296585 , Validation Accuracy: 0.5058 , Test Loss: 13.759644985198975 , Test Accuracy: 0.5218 , Timing: 38.49828100204468\n",
            "[07/05 07:01:55] __main__ INFO: Epoch: 12 , Validation Loss: 323.9589182138443 , Validation Accuracy: 0.5204 , Test Loss: 12.521627187728882 , Test Accuracy: 0.5221 , Timing: 6.190110445022583\n",
            "[07/05 07:02:08] __main__ INFO: Epoch: 13 , Validation Loss: 332.5692104101181 , Validation Accuracy: 0.5362 , Test Loss: 12.791628360748291 , Test Accuracy: 0.5418 , Timing: 6.2123777866363525\n",
            "[07/05 07:02:20] __main__ INFO: Epoch: 14 , Validation Loss: 297.5464963912964 , Validation Accuracy: 0.5682 , Test Loss: 11.64517629146576 , Test Accuracy: 0.5752 , Timing: 6.169388771057129\n",
            "[07/05 07:02:33] __main__ INFO: Epoch: 15 , Validation Loss: 306.22368985414505 , Validation Accuracy: 0.5406 , Test Loss: 11.896168231964111 , Test Accuracy: 0.5632 , Timing: 6.16928505897522\n",
            "[07/05 07:02:46] __main__ INFO: Epoch: 16 , Validation Loss: 299.9967794418335 , Validation Accuracy: 0.5614 , Test Loss: 11.375681281089783 , Test Accuracy: 0.5941 , Timing: 6.204183101654053\n",
            "[07/05 07:02:59] __main__ INFO: Epoch: 17 , Validation Loss: 289.16392093896866 , Validation Accuracy: 0.5806 , Test Loss: 11.438340425491333 , Test Accuracy: 0.5871 , Timing: 6.214186668395996\n",
            "[07/05 07:03:11] __main__ INFO: Epoch: 18 , Validation Loss: 329.45895105600357 , Validation Accuracy: 0.5166 , Test Loss: 12.995336413383484 , Test Accuracy: 0.5335 , Timing: 6.154619932174683\n",
            "[07/05 07:03:24] __main__ INFO: Epoch: 19 , Validation Loss: 269.9692197740078 , Validation Accuracy: 0.6148 , Test Loss: 10.501977920532227 , Test Accuracy: 0.6316 , Timing: 6.210459470748901\n",
            "[07/05 07:03:37] __main__ INFO: Epoch: 20 , Validation Loss: 265.70712018013 , Validation Accuracy: 0.6004 , Test Loss: 10.221830606460571 , Test Accuracy: 0.6212 , Timing: 6.165725946426392\n",
            "[07/05 07:03:37] __main__ INFO: Model checkpoint saved at epoch: 20\n",
            "[07/05 07:04:09] __main__ INFO: Epoch: 21, GLISTER dataloader subset selection finished, takes 32.1489. \n",
            "[07/05 07:04:22] __main__ INFO: Epoch: 21 , Validation Loss: 238.93530967831612 , Validation Accuracy: 0.6646 , Test Loss: 9.13410347700119 , Test Accuracy: 0.672 , Timing: 38.35549330711365\n",
            "[07/05 07:04:35] __main__ INFO: Epoch: 22 , Validation Loss: 228.51127594709396 , Validation Accuracy: 0.6706 , Test Loss: 8.839591443538666 , Test Accuracy: 0.6722 , Timing: 6.18008279800415\n",
            "[07/05 07:04:48] __main__ INFO: Epoch: 23 , Validation Loss: 209.18820637464523 , Validation Accuracy: 0.6964 , Test Loss: 8.113229990005493 , Test Accuracy: 0.702 , Timing: 6.194049596786499\n",
            "[07/05 07:05:01] __main__ INFO: Epoch: 24 , Validation Loss: 217.9474068582058 , Validation Accuracy: 0.6794 , Test Loss: 8.722123801708221 , Test Accuracy: 0.6847 , Timing: 6.182433843612671\n",
            "[07/05 07:05:13] __main__ INFO: Epoch: 25 , Validation Loss: 200.55135035514832 , Validation Accuracy: 0.7078 , Test Loss: 8.015113413333893 , Test Accuracy: 0.7114 , Timing: 6.15485954284668\n",
            "[07/05 07:05:26] __main__ INFO: Epoch: 26 , Validation Loss: 195.0119611620903 , Validation Accuracy: 0.7094 , Test Loss: 7.756093144416809 , Test Accuracy: 0.722 , Timing: 6.1734912395477295\n",
            "[07/05 07:05:39] __main__ INFO: Epoch: 27 , Validation Loss: 194.42663851380348 , Validation Accuracy: 0.7164 , Test Loss: 7.761498034000397 , Test Accuracy: 0.7231 , Timing: 6.173920392990112\n",
            "[07/05 07:05:52] __main__ INFO: Epoch: 28 , Validation Loss: 187.51648584008217 , Validation Accuracy: 0.7202 , Test Loss: 7.502269446849823 , Test Accuracy: 0.7297 , Timing: 6.187304735183716\n",
            "[07/05 07:06:04] __main__ INFO: Epoch: 29 , Validation Loss: 185.36862069368362 , Validation Accuracy: 0.7326 , Test Loss: 7.45535409450531 , Test Accuracy: 0.734 , Timing: 6.1577746868133545\n",
            "[07/05 07:06:17] __main__ INFO: Epoch: 30 , Validation Loss: 186.4561886191368 , Validation Accuracy: 0.723 , Test Loss: 7.49738609790802 , Test Accuracy: 0.7353 , Timing: 6.166403770446777\n",
            "[07/05 07:06:17] __main__ INFO: GLISTER Selection Run---------------------------------\n",
            "[07/05 07:06:17] __main__ INFO: Final SubsetTrn: 208.855114\n",
            "[07/05 07:06:17] __main__ INFO: Validation Loss: 186.46 , Validation Accuracy: 0.72\n",
            "[07/05 07:06:17] __main__ INFO: Test Loss: 7.50, Test Accuracy: 0.74\n",
            "[07/05 07:06:17] __main__ INFO: ---------------------------------------------------------------------\n",
            "[07/05 07:06:17] __main__ INFO: GLISTER\n",
            "[07/05 07:06:17] __main__ INFO: ---------------------------------------------------------------------\n",
            "[07/05 07:06:17] __main__ INFO: Validation Accuracy,  , 0.2712 , 0.3304 , 0.3408 , 0.3798 , 0.4378 , 0.4544 , 0.4702 , 0.5046 , 0.523 , 0.5496 , 0.5058 , 0.5204 , 0.5362 , 0.5682 , 0.5406 , 0.5614 , 0.5806 , 0.5166 , 0.6148 , 0.6004 , 0.6646 , 0.6706 , 0.6964 , 0.6794 , 0.7078 , 0.7094 , 0.7164 , 0.7202 , 0.7326 , 0.723\n",
            "[07/05 07:06:17] __main__ INFO: Test Accuracy,  , 0.2861 , 0.3377 , 0.3626 , 0.3771 , 0.438 , 0.4569 , 0.485 , 0.5117 , 0.5333 , 0.5625 , 0.5218 , 0.5221 , 0.5418 , 0.5752 , 0.5632 , 0.5941 , 0.5871 , 0.5335 , 0.6316 , 0.6212 , 0.672 , 0.6722 , 0.702 , 0.6847 , 0.7114 , 0.722 , 0.7231 , 0.7297 , 0.734 , 0.7353\n",
            "[07/05 07:06:17] __main__ INFO: [6.719554662704468, 6.184462308883667, 6.232213497161865, 6.179301738739014, 6.223090648651123, 6.186913967132568, 6.183251857757568, 6.198957681655884, 6.228888273239136, 6.207472324371338, 38.49828100204468, 6.190110445022583, 6.2123777866363525, 6.169388771057129, 6.16928505897522, 6.204183101654053, 6.214186668395996, 6.154619932174683, 6.210459470748901, 6.165725946426392, 38.35549330711365, 6.18008279800415, 6.194049596786499, 6.182433843612671, 6.15485954284668, 6.1734912395477295, 6.173920392990112, 6.187304735183716, 6.1577746868133545, 6.166403770446777]\n",
            "[07/05 07:06:17] __main__ INFO: Total time taken by GLISTER = 0.0696 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Average Time / Epoch: {np.mean(timing)} \\nTotal Epochs: {num_epochs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEw6yODiL_CJ",
        "outputId": "51fe5a99-d910-4693-e925-1dd26846212b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Time / Epoch: 8.355284635225932 \n",
            "Total Epochs: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "OiR1Rbi5CgrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc57d883-95f5-4d4c-b728-ebf4db6162ba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul  5 07:06:17 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P0    43W / 250W |   7409MiB / 16280MiB |     98%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9hnoIcO1L1iy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}