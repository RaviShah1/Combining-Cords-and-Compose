{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Combining Coords and Composer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaviShah1/Combining-Cords-and-Compose/blob/main/experiments/resnet18_cifar10/glister_label_smoothing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/decile-team/cords.git\n",
        "%cd cords\n",
        "%ls"
      ],
      "metadata": {
        "id": "pJewp117QDUI",
        "outputId": "fab1d33b-e51e-42de-8c45-7be950ca3239",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cords' already exists and is not an empty directory.\n",
            "/content/cords\n",
            "\u001b[0m\u001b[01;34mbenchmarks\u001b[0m/   \u001b[01;34mcords\u001b[0m/  \u001b[01;34mexamples\u001b[0m/    README.md      setup.py      train_sl.py\n",
            "CITATION.CFF  \u001b[01;34mdata\u001b[0m/   LICENSE.txt  \u001b[01;34mrequirements\u001b[0m/  \u001b[01;34mtests\u001b[0m/        train_ssl.py\n",
            "\u001b[01;34mconfigs\u001b[0m/      \u001b[01;34mdocs\u001b[0m/   model.pt     \u001b[01;34mresults\u001b[0m/       train_hpo.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dotmap apricot-select ray[default] ray[tune] mosaicml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37QszJkXYAZz",
        "outputId": "5032d1d2-1854-43b4-e54e-12eba44c1992"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dotmap in /usr/local/lib/python3.7/dist-packages (1.3.30)\n",
            "Requirement already satisfied: apricot-select in /usr/local/lib/python3.7/dist-packages (0.6.1)\n",
            "Requirement already satisfied: ray[default] in /usr/local/lib/python3.7/dist-packages (1.13.0)\n",
            "Requirement already satisfied: mosaicml in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from apricot-select) (1.3.7)\n",
            "Requirement already satisfied: tqdm>=4.24.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (0.51.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->apricot-select) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->apricot-select) (0.34.0)\n",
            "Requirement already satisfied: requests<3,>=2.26.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (2.28.1)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (0.12.0+cu113)\n",
            "Requirement already satisfied: coolname<2,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (1.1.0)\n",
            "Requirement already satisfied: torch<2,>=1.9 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (1.11.0+cu113)\n",
            "Requirement already satisfied: pyyaml<7,>=6.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (6.0)\n",
            "Requirement already satisfied: torchmetrics<0.8,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (0.7.3)\n",
            "Requirement already satisfied: psutil<6,>=5.8.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (5.9.1)\n",
            "Requirement already satisfied: yahp<0.2,>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (0.1.1)\n",
            "Requirement already satisfied: py-cpuinfo>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (8.0.0)\n",
            "Requirement already satisfied: torch-optimizer<0.2,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (0.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.26.0->mosaicml) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.26.0->mosaicml) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.26.0->mosaicml) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.26.0->mosaicml) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.9->mosaicml) (4.1.1)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from torch-optimizer<0.2,>=0.1.0->mosaicml) (0.1.1)\n",
            "Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.7/dist-packages (from torchmetrics<0.8,>=0.7.0->mosaicml) (0.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics<0.8,>=0.7.0->mosaicml) (21.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.10.0->mosaicml) (7.1.2)\n",
            "Requirement already satisfied: docstring-parser<=0.15,>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from yahp<0.2,>=0.1.1->mosaicml) (0.14.1)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.10 in /usr/local/lib/python3.7/dist-packages (from yahp<0.2,>=0.1.1->mosaicml) (0.17.21)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.17.10->yahp<0.2,>=0.1.1->mosaicml) (0.2.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics<0.8,>=0.7.0->mosaicml) (3.0.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.7.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.0.4)\n",
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.7/dist-packages (from ray[default]) (20.15.1)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.17.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[default]) (21.4.0)\n",
            "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.43.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]) (4.3.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.2.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.3.0)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (7.1.2)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.3.12)\n",
            "Requirement already satisfied: prometheus-client<0.14.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.13.1)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.7.0)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.8.1)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.9.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]) (5.2.1)\n",
            "Requirement already satisfied: gpustat>=1.0.0b1 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.0.0rc1)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.5.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]) (1.7.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]) (4.0.2)\n",
            "Requirement already satisfied: nvidia-ml-py<=11.495.46,>=11.450.129 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]) (11.495.46)\n",
            "Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]) (1.19.1)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]) (1.15.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[default]) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]) (4.11.4)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]) (5.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray[default]) (3.8.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]) (0.1.2)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]) (1.31.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (1.56.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (2022.1)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (4.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (0.4.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.8.9)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (2.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[default]) (2.8.2)\n",
            "Requirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.7/dist-packages (from virtualenv->ray[default]) (2.5.2)\n",
            "Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv->ray[default]) (0.3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from cords.utils.data.datasets.SL import gen_dataset\n",
        "from torch.utils.data import Subset\n",
        "from cords.utils.config_utils import load_config_data\n",
        "import os.path as osp\n",
        "from cords.utils.data.data_utils import WeightedSubset\n",
        "from composer import functional as cf\n",
        "from ray import tune"
      ],
      "metadata": {
        "id": "IFtimJsDYBSm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, validset, testset, num_cls = gen_dataset('data/', 'cifar10', None, isnumpy=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCOZOz0CYDmA",
        "outputId": "02c806c4-dfa7-4ef4-e004-d46e57d40c8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trn_batch_size = 20\n",
        "val_batch_size = 20\n",
        "tst_batch_size = 1000\n",
        "\n",
        "# Creating the Data Loaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=trn_batch_size,\n",
        "                                          shuffle=False, pin_memory=True)\n",
        "\n",
        "valloader = torch.utils.data.DataLoader(validset, batch_size=val_batch_size,\n",
        "                                        shuffle=False, pin_memory=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=tst_batch_size,\n",
        "                                          shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "JJji-yh0YIEY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cords.utils.models import ResNet18\n",
        "numclasses = 10\n",
        "device = 'cuda' #Device Argument\n",
        "model = ResNet18(10)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "6Qj5KIyEYJ8M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion_nored = nn.CrossEntropyLoss(reduction='none')"
      ],
      "metadata": {
        "id": "8Tvpow1wYLWZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_ckpt(state, ckpt_path):\n",
        "    torch.save(state, ckpt_path)\n",
        "\n",
        "\n",
        "def load_ckpt(ckpt_path, model, optimizer):\n",
        "    checkpoint = torch.load(ckpt_path)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    loss = checkpoint['loss']\n",
        "    metrics = checkpoint['metrics']\n",
        "    return start_epoch, model, optimizer, loss, metrics"
      ],
      "metadata": {
        "id": "uJhZ8d3vYNBh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_cumulative_timing(mod_timing):\n",
        "    tmp = 0\n",
        "    mod_cum_timing = np.zeros(len(mod_timing))\n",
        "    for i in range(len(mod_timing)):\n",
        "        tmp += mod_timing[i]\n",
        "        mod_cum_timing[i] = tmp\n",
        "    return mod_cum_timing / 3600"
      ],
      "metadata": {
        "id": "0hx_sinTYOdX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=1e-2,\n",
        "                                  momentum=0.9,\n",
        "                                  weight_decay=5e-4,\n",
        "                                  nesterov=False)\n",
        "\n",
        "#T_max is the maximum number of scheduler steps. Here we are using the number of epochs as the maximum number of scheduler steps.\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "                                                       T_max=30)"
      ],
      "metadata": {
        "id": "kLHSf3WEYP3_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def __get_logger(results_dir):\n",
        "  os.makedirs(results_dir, exist_ok=True)\n",
        "  # setup logger\n",
        "  plain_formatter = logging.Formatter(\"[%(asctime)s] %(name)s %(levelname)s: %(message)s\",\n",
        "                                      datefmt=\"%m/%d %H:%M:%S\")\n",
        "  logger = logging.getLogger(__name__)\n",
        "  logger.setLevel(logging.INFO)\n",
        "  s_handler = logging.StreamHandler(stream=sys.stdout)\n",
        "  s_handler.setFormatter(plain_formatter)\n",
        "  s_handler.setLevel(logging.INFO)\n",
        "  logger.addHandler(s_handler)\n",
        "  f_handler = logging.FileHandler(os.path.join(results_dir, \"results.log\"))\n",
        "  f_handler.setFormatter(plain_formatter)\n",
        "  f_handler.setLevel(logging.DEBUG)\n",
        "  logger.addHandler(f_handler)\n",
        "  logger.propagate = False\n",
        "  return logger"
      ],
      "metadata": {
        "id": "wAopp5oFYRJJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import os.path as osp\n",
        "import sys\n",
        "\n",
        "#Results logging directory\n",
        "results_dir = osp.abspath(osp.expanduser('results'))\n",
        "logger = __get_logger(results_dir)"
      ],
      "metadata": {
        "id": "6AQkQW5XYSqA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info(\"hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAh0aXRKYWzi",
        "outputId": "6b62d1a1-254d-47e7-bb2c-530595220663"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07/05 08:15:03] __main__ INFO: hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cords.utils.data.dataloader.SL.adaptive import GLISTERDataLoader, OLRandomDataLoader, \\\n",
        "    CRAIGDataLoader, GradMatchDataLoader, RandomDataLoader\n",
        "from dotmap import DotMap\n",
        "\n",
        "selection_strategy = 'GLISTER'\n",
        "dss_args = dict(model=model,\n",
        "                loss=criterion_nored,\n",
        "                eta=0.01,\n",
        "                num_classes=10,\n",
        "                num_epochs=30,\n",
        "                device='cuda',\n",
        "                fraction=0.1,\n",
        "                select_every=10,\n",
        "                kappa=0,\n",
        "                linear_layer=False,\n",
        "                selection_type='SL',\n",
        "                greedy='Stochastic')\n",
        "dss_args = DotMap(dss_args)\n",
        "\n",
        "dataloader = GLISTERDataLoader(trainloader, valloader, dss_args, logger, \n",
        "                                  batch_size=20, \n",
        "                                  shuffle=True,\n",
        "                                  pin_memory=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P72TwdhcYYL8",
        "outputId": "315a0832-a113-4f69-8127-e8720ec1669e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\u001b[0m\n",
            "  warnings.warn(problem)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Arguments\n",
        "num_epochs = 30\n",
        "\n",
        "#Arguments for results logging\n",
        "print_every = 1\n",
        "print_args = [\"val_loss\", \"val_acc\", \"tst_loss\", \"tst_acc\", \"time\"]\n",
        "\n",
        "#Argumets for checkpointing\n",
        "save_every = 20\n",
        "is_save = True\n",
        "\n",
        "#Evaluation Metrics\n",
        "trn_losses = list()\n",
        "val_losses = list()\n",
        "tst_losses = list()\n",
        "subtrn_losses = list()\n",
        "timing = list()\n",
        "trn_acc = list()\n",
        "val_acc = list()  \n",
        "tst_acc = list()  \n",
        "subtrn_acc = list()"
      ],
      "metadata": {
        "id": "hN182L3MYa8a"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "################################################# Training Loop #################################################\n",
        "\"\"\"\n",
        "for epoch in range(num_epochs):\n",
        "    subtrn_loss = 0\n",
        "    subtrn_correct = 0\n",
        "    subtrn_total = 0\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    for _, (inputs, targets, weights) in enumerate(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "        weights = weights.to(device)  \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        losses = criterion_nored(outputs, targets)\n",
        "        loss = torch.dot(losses, weights/(weights.sum()))\n",
        "        loss.backward()\n",
        "        subtrn_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        _, predicted = outputs.max(1)\n",
        "        subtrn_total += targets.size(0)\n",
        "        subtrn_correct += predicted.eq(targets).sum().item()\n",
        "    epoch_time = time.time() - start_time\n",
        "    scheduler.step()\n",
        "    timing.append(epoch_time)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    ################################################# Evaluation Loop #################################################\n",
        "    \"\"\"\n",
        "\n",
        "    if (epoch + 1) % print_every == 0:\n",
        "        trn_loss = 0\n",
        "        trn_correct = 0\n",
        "        trn_total = 0\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        tst_correct = 0\n",
        "        tst_total = 0\n",
        "        tst_loss = 0\n",
        "        model.eval()\n",
        "\n",
        "        if (\"trn_loss\" in print_args) or (\"trn_acc\" in print_args):\n",
        "            with torch.no_grad():\n",
        "                for _, (inputs, targets) in enumerate(trainloader):\n",
        "                    inputs, targets = inputs.to(device), \\\n",
        "                                      targets.to(device, non_blocking=True)\n",
        "                    outputs = model(inputs)\n",
        "                    # Label Smoothing\n",
        "                    smoothed_targets = cf.smooth_labels(outputs, targets, smoothing=0.1)\n",
        "                    loss = criterion(outputs, smoothed_targets)\n",
        "                    trn_loss += loss.item()\n",
        "                    if \"trn_acc\" in print_args:\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        trn_total += targets.size(0)\n",
        "                        trn_correct += predicted.eq(targets).sum().item()\n",
        "                trn_losses.append(trn_loss)\n",
        "\n",
        "            if \"trn_acc\" in print_args:\n",
        "                trn_acc.append(trn_correct / trn_total)\n",
        "\n",
        "        if (\"val_loss\" in print_args) or (\"val_acc\" in print_args):\n",
        "            with torch.no_grad():\n",
        "                for _, (inputs, targets) in enumerate(valloader):\n",
        "                    inputs, targets = inputs.to(device), \\\n",
        "                                      targets.to(device, non_blocking=True)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    val_loss += loss.item()\n",
        "                    if \"val_acc\" in print_args:\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        val_total += targets.size(0)\n",
        "                        val_correct += predicted.eq(targets).sum().item()\n",
        "                val_losses.append(val_loss)\n",
        "\n",
        "            if \"val_acc\" in print_args:\n",
        "                val_acc.append(val_correct / val_total)\n",
        "\n",
        "        if (\"tst_loss\" in print_args) or (\"tst_acc\" in print_args):\n",
        "            with torch.no_grad():\n",
        "                for _, (inputs, targets) in enumerate(testloader):\n",
        "                    inputs, targets = inputs.to(device), \\\n",
        "                                      targets.to(device, non_blocking=True)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    tst_loss += loss.item()\n",
        "                    if \"tst_acc\" in print_args:\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        tst_total += targets.size(0)\n",
        "                        tst_correct += predicted.eq(targets).sum().item()\n",
        "                tst_losses.append(tst_loss)\n",
        "\n",
        "            if \"tst_acc\" in print_args:\n",
        "                tst_acc.append(tst_correct / tst_total)\n",
        "\n",
        "        if \"subtrn_acc\" in print_args:\n",
        "            subtrn_acc.append(subtrn_correct / subtrn_total)\n",
        "\n",
        "        if \"subtrn_losses\" in print_args:\n",
        "            subtrn_losses.append(subtrn_loss)\n",
        "\n",
        "        print_str = \"Epoch: \" + str(epoch + 1)\n",
        "\n",
        "        \"\"\"\n",
        "        ################################################# Results Printing #################################################\n",
        "        \"\"\"\n",
        "\n",
        "        for arg in print_args:\n",
        "\n",
        "            if arg == \"val_loss\":\n",
        "                print_str += \" , \" + \"Validation Loss: \" + str(val_losses[-1])\n",
        "\n",
        "            if arg == \"val_acc\":\n",
        "                print_str += \" , \" + \"Validation Accuracy: \" + str(val_acc[-1])\n",
        "\n",
        "            if arg == \"tst_loss\":\n",
        "                print_str += \" , \" + \"Test Loss: \" + str(tst_losses[-1])\n",
        "\n",
        "            if arg == \"tst_acc\":\n",
        "                print_str += \" , \" + \"Test Accuracy: \" + str(tst_acc[-1])\n",
        "\n",
        "            if arg == \"trn_loss\":\n",
        "                print_str += \" , \" + \"Training Loss: \" + str(trn_losses[-1])\n",
        "\n",
        "            if arg == \"trn_acc\":\n",
        "                print_str += \" , \" + \"Training Accuracy: \" + str(trn_acc[-1])\n",
        "\n",
        "            if arg == \"subtrn_loss\":\n",
        "                print_str += \" , \" + \"Subset Loss: \" + str(subtrn_losses[-1])\n",
        "\n",
        "            if arg == \"subtrn_acc\":\n",
        "                print_str += \" , \" + \"Subset Accuracy: \" + str(subtrn_acc[-1])\n",
        "\n",
        "            if arg == \"time\":\n",
        "                print_str += \" , \" + \"Timing: \" + str(timing[-1])\n",
        "\n",
        "        logger.info(print_str)\n",
        "\n",
        "    \"\"\"\n",
        "    ################################################# Checkpoint Saving #################################################\n",
        "    \"\"\"\n",
        "\n",
        "    if ((epoch + 1) % save_every == 0) and is_save:\n",
        "\n",
        "        metric_dict = {}\n",
        "\n",
        "        for arg in print_args:\n",
        "            if arg == \"val_loss\":\n",
        "                metric_dict['val_loss'] = val_losses\n",
        "            if arg == \"val_acc\":\n",
        "                metric_dict['val_acc'] = val_acc\n",
        "            if arg == \"tst_loss\":\n",
        "                metric_dict['tst_loss'] = tst_losses\n",
        "            if arg == \"tst_acc\":\n",
        "                metric_dict['tst_acc'] = tst_acc\n",
        "            if arg == \"trn_loss\":\n",
        "                metric_dict['trn_loss'] = trn_losses\n",
        "            if arg == \"trn_acc\":\n",
        "                metric_dict['trn_acc'] = trn_acc\n",
        "            if arg == \"subtrn_loss\":\n",
        "                metric_dict['subtrn_loss'] = subtrn_losses\n",
        "            if arg == \"subtrn_acc\":\n",
        "                metric_dict['subtrn_acc'] = subtrn_acc\n",
        "            if arg == \"time\":\n",
        "                metric_dict['time'] = timing\n",
        "\n",
        "        ckpt_state = {\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'loss': criterion_nored,\n",
        "            'metrics': metric_dict\n",
        "        }\n",
        "\n",
        "        # save checkpoint\n",
        "        save_ckpt(ckpt_state, 'model.pt')\n",
        "        logger.info(\"Model checkpoint saved at epoch: {0:d}\".format(epoch + 1))\n",
        "\n",
        "\"\"\"\n",
        "################################################# Results Summary #################################################\n",
        "\"\"\"\n",
        "\n",
        "logger.info(\"{0:s} Selection Run---------------------------------\".format(selection_strategy))\n",
        "logger.info(\"Final SubsetTrn: {0:f}\".format(subtrn_loss))\n",
        "if \"val_loss\" in print_args:\n",
        "    if \"val_acc\" in print_args:\n",
        "        logger.info(\"Validation Loss: %.2f , Validation Accuracy: %.2f\", val_loss, val_acc[-1])\n",
        "    else:\n",
        "        logger.info(\"Validation Loss: %.2f\", val_loss)\n",
        "\n",
        "if \"tst_loss\" in print_args:\n",
        "    if \"tst_acc\" in print_args:\n",
        "        logger.info(\"Test Loss: %.2f, Test Accuracy: %.2f\", tst_loss, tst_acc[-1])\n",
        "    else:\n",
        "        logger.info(\"Test Data Loss: %f\", tst_loss)\n",
        "logger.info('---------------------------------------------------------------------')\n",
        "logger.info(selection_strategy)\n",
        "logger.info('---------------------------------------------------------------------')\n",
        "\n",
        "\"\"\"\n",
        "################################################# Final Results Logging #################################################\n",
        "\"\"\"\n",
        "\n",
        "if \"val_acc\" in print_args:\n",
        "    val_str = \"Validation Accuracy, \"\n",
        "    for val in val_acc:\n",
        "        val_str = val_str + \" , \" + str(val)\n",
        "    logger.info(val_str)\n",
        "\n",
        "if \"tst_acc\" in print_args:\n",
        "    tst_str = \"Test Accuracy, \"\n",
        "    for tst in tst_acc:\n",
        "        tst_str = tst_str + \" , \" + str(tst)\n",
        "    logger.info(tst_str)\n",
        "\n",
        "if \"time\" in print_args:\n",
        "    time_str = \"Time, \"\n",
        "    for t in timing:\n",
        "        time_str = time_str + \" , \" + str(t)\n",
        "    logger.info(timing)\n",
        "\n",
        "timing_array = np.array(timing)\n",
        "cum_timing = list(generate_cumulative_timing(timing_array))\n",
        "logger.info(\"Total time taken by %s = %.4f \", selection_strategy, cum_timing[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "243ksusPYc59",
        "outputId": "f4051e49-87f4-4809-904a-c94d80a5d169"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07/05 08:15:20] __main__ INFO: Epoch: 1 , Validation Loss: 482.4688198566437 , Validation Accuracy: 0.2932 , Test Loss: 18.870927929878235 , Test Accuracy: 0.3101 , Timing: 6.27840256690979\n",
            "[07/05 08:15:33] __main__ INFO: Epoch: 2 , Validation Loss: 454.45346784591675 , Validation Accuracy: 0.3728 , Test Loss: 17.59542441368103 , Test Accuracy: 0.3932 , Timing: 6.191172122955322\n",
            "[07/05 08:15:45] __main__ INFO: Epoch: 3 , Validation Loss: 432.43728971481323 , Validation Accuracy: 0.3524 , Test Loss: 17.300525546073914 , Test Accuracy: 0.362 , Timing: 6.175506591796875\n",
            "[07/05 08:15:59] __main__ INFO: Epoch: 4 , Validation Loss: 414.9170439839363 , Validation Accuracy: 0.3908 , Test Loss: 16.099459052085876 , Test Accuracy: 0.4042 , Timing: 6.475172758102417\n",
            "[07/05 08:16:11] __main__ INFO: Epoch: 5 , Validation Loss: 431.4976079463959 , Validation Accuracy: 0.3876 , Test Loss: 16.197259664535522 , Test Accuracy: 0.4159 , Timing: 6.224555730819702\n",
            "[07/05 08:16:24] __main__ INFO: Epoch: 6 , Validation Loss: 368.6268592476845 , Validation Accuracy: 0.4574 , Test Loss: 14.519585609436035 , Test Accuracy: 0.4712 , Timing: 6.174053430557251\n",
            "[07/05 08:16:37] __main__ INFO: Epoch: 7 , Validation Loss: 388.470955491066 , Validation Accuracy: 0.4376 , Test Loss: 14.717355728149414 , Test Accuracy: 0.4713 , Timing: 6.196956396102905\n",
            "[07/05 08:16:50] __main__ INFO: Epoch: 8 , Validation Loss: 352.5092253088951 , Validation Accuracy: 0.474 , Test Loss: 14.101244568824768 , Test Accuracy: 0.4898 , Timing: 6.173452854156494\n",
            "[07/05 08:17:03] __main__ INFO: Epoch: 9 , Validation Loss: 326.7227607369423 , Validation Accuracy: 0.5344 , Test Loss: 12.78763473033905 , Test Accuracy: 0.5446 , Timing: 6.198770999908447\n",
            "[07/05 08:17:15] __main__ INFO: Epoch: 10 , Validation Loss: 307.1313251852989 , Validation Accuracy: 0.5526 , Test Loss: 12.105613827705383 , Test Accuracy: 0.568 , Timing: 6.174286842346191\n",
            "[07/05 08:17:48] __main__ INFO: Epoch: 11, GLISTER dataloader subset selection finished, takes 32.3309. \n",
            "[07/05 08:18:00] __main__ INFO: Epoch: 11 , Validation Loss: 356.0954290628433 , Validation Accuracy: 0.4682 , Test Loss: 13.760719895362854 , Test Accuracy: 0.4788 , Timing: 38.526896476745605\n",
            "[07/05 08:18:13] __main__ INFO: Epoch: 12 , Validation Loss: 332.12078726291656 , Validation Accuracy: 0.4894 , Test Loss: 12.994844913482666 , Test Accuracy: 0.4888 , Timing: 6.1778013706207275\n",
            "[07/05 08:18:26] __main__ INFO: Epoch: 13 , Validation Loss: 336.30332285165787 , Validation Accuracy: 0.4768 , Test Loss: 13.116148471832275 , Test Accuracy: 0.4935 , Timing: 6.225937366485596\n",
            "[07/05 08:18:39] __main__ INFO: Epoch: 14 , Validation Loss: 312.8580797314644 , Validation Accuracy: 0.5168 , Test Loss: 12.173159837722778 , Test Accuracy: 0.5275 , Timing: 6.188424348831177\n",
            "[07/05 08:18:52] __main__ INFO: Epoch: 15 , Validation Loss: 342.19644248485565 , Validation Accuracy: 0.4614 , Test Loss: 13.508469223976135 , Test Accuracy: 0.4663 , Timing: 6.220351696014404\n",
            "[07/05 08:19:05] __main__ INFO: Epoch: 16 , Validation Loss: 311.1589831709862 , Validation Accuracy: 0.542 , Test Loss: 12.430546283721924 , Test Accuracy: 0.5346 , Timing: 6.206094264984131\n",
            "[07/05 08:19:17] __main__ INFO: Epoch: 17 , Validation Loss: 322.71588933467865 , Validation Accuracy: 0.495 , Test Loss: 13.02778160572052 , Test Accuracy: 0.5065 , Timing: 6.186597108840942\n",
            "[07/05 08:19:30] __main__ INFO: Epoch: 18 , Validation Loss: 279.7061977982521 , Validation Accuracy: 0.582 , Test Loss: 10.952908635139465 , Test Accuracy: 0.5866 , Timing: 6.2140679359436035\n",
            "[07/05 08:19:43] __main__ INFO: Epoch: 19 , Validation Loss: 274.7086542248726 , Validation Accuracy: 0.593 , Test Loss: 10.595878958702087 , Test Accuracy: 0.6115 , Timing: 6.426660537719727\n",
            "[07/05 08:19:56] __main__ INFO: Epoch: 20 , Validation Loss: 254.78968036174774 , Validation Accuracy: 0.6186 , Test Loss: 10.22476041316986 , Test Accuracy: 0.6303 , Timing: 6.199953317642212\n",
            "[07/05 08:19:56] __main__ INFO: Model checkpoint saved at epoch: 20\n",
            "[07/05 08:20:29] __main__ INFO: Epoch: 21, GLISTER dataloader subset selection finished, takes 32.5818. \n",
            "[07/05 08:20:42] __main__ INFO: Epoch: 21 , Validation Loss: 237.75568583607674 , Validation Accuracy: 0.6658 , Test Loss: 9.041308999061584 , Test Accuracy: 0.6724 , Timing: 38.807260036468506\n",
            "[07/05 08:20:55] __main__ INFO: Epoch: 22 , Validation Loss: 222.5044346153736 , Validation Accuracy: 0.6852 , Test Loss: 8.552714407444 , Test Accuracy: 0.6913 , Timing: 6.19922661781311\n",
            "[07/05 08:21:07] __main__ INFO: Epoch: 23 , Validation Loss: 230.52954179048538 , Validation Accuracy: 0.6606 , Test Loss: 8.874077200889587 , Test Accuracy: 0.6665 , Timing: 6.20571756362915\n",
            "[07/05 08:21:20] __main__ INFO: Epoch: 24 , Validation Loss: 208.3238478899002 , Validation Accuracy: 0.6984 , Test Loss: 8.342242181301117 , Test Accuracy: 0.6976 , Timing: 6.202898263931274\n",
            "[07/05 08:21:33] __main__ INFO: Epoch: 25 , Validation Loss: 201.4688221514225 , Validation Accuracy: 0.7062 , Test Loss: 7.840171754360199 , Test Accuracy: 0.715 , Timing: 6.219465017318726\n",
            "[07/05 08:21:46] __main__ INFO: Epoch: 26 , Validation Loss: 197.30172249674797 , Validation Accuracy: 0.7038 , Test Loss: 7.572137117385864 , Test Accuracy: 0.7274 , Timing: 6.197426795959473\n",
            "[07/05 08:21:59] __main__ INFO: Epoch: 27 , Validation Loss: 195.65610641241074 , Validation Accuracy: 0.7128 , Test Loss: 7.571650743484497 , Test Accuracy: 0.7299 , Timing: 6.185598850250244\n",
            "[07/05 08:22:11] __main__ INFO: Epoch: 28 , Validation Loss: 188.60889172554016 , Validation Accuracy: 0.7278 , Test Loss: 7.471666753292084 , Test Accuracy: 0.7331 , Timing: 6.175104856491089\n",
            "[07/05 08:22:24] __main__ INFO: Epoch: 29 , Validation Loss: 186.82037857174873 , Validation Accuracy: 0.7268 , Test Loss: 7.294740796089172 , Test Accuracy: 0.7387 , Timing: 6.180721044540405\n",
            "[07/05 08:22:37] __main__ INFO: Epoch: 30 , Validation Loss: 187.88343805074692 , Validation Accuracy: 0.7224 , Test Loss: 7.280500650405884 , Test Accuracy: 0.7407 , Timing: 6.184389591217041\n",
            "[07/05 08:22:37] __main__ INFO: GLISTER Selection Run---------------------------------\n",
            "[07/05 08:22:37] __main__ INFO: Final SubsetTrn: 204.883925\n",
            "[07/05 08:22:37] __main__ INFO: Validation Loss: 187.88 , Validation Accuracy: 0.72\n",
            "[07/05 08:22:37] __main__ INFO: Test Loss: 7.28, Test Accuracy: 0.74\n",
            "[07/05 08:22:37] __main__ INFO: ---------------------------------------------------------------------\n",
            "[07/05 08:22:37] __main__ INFO: GLISTER\n",
            "[07/05 08:22:37] __main__ INFO: ---------------------------------------------------------------------\n",
            "[07/05 08:22:37] __main__ INFO: Validation Accuracy,  , 0.2932 , 0.3728 , 0.3524 , 0.3908 , 0.3876 , 0.4574 , 0.4376 , 0.474 , 0.5344 , 0.5526 , 0.4682 , 0.4894 , 0.4768 , 0.5168 , 0.4614 , 0.542 , 0.495 , 0.582 , 0.593 , 0.6186 , 0.6658 , 0.6852 , 0.6606 , 0.6984 , 0.7062 , 0.7038 , 0.7128 , 0.7278 , 0.7268 , 0.7224\n",
            "[07/05 08:22:37] __main__ INFO: Test Accuracy,  , 0.3101 , 0.3932 , 0.362 , 0.4042 , 0.4159 , 0.4712 , 0.4713 , 0.4898 , 0.5446 , 0.568 , 0.4788 , 0.4888 , 0.4935 , 0.5275 , 0.4663 , 0.5346 , 0.5065 , 0.5866 , 0.6115 , 0.6303 , 0.6724 , 0.6913 , 0.6665 , 0.6976 , 0.715 , 0.7274 , 0.7299 , 0.7331 , 0.7387 , 0.7407\n",
            "[07/05 08:22:37] __main__ INFO: [6.27840256690979, 6.191172122955322, 6.175506591796875, 6.475172758102417, 6.224555730819702, 6.174053430557251, 6.196956396102905, 6.173452854156494, 6.198770999908447, 6.174286842346191, 38.526896476745605, 6.1778013706207275, 6.225937366485596, 6.188424348831177, 6.220351696014404, 6.206094264984131, 6.186597108840942, 6.2140679359436035, 6.426660537719727, 6.199953317642212, 38.807260036468506, 6.19922661781311, 6.20571756362915, 6.202898263931274, 6.219465017318726, 6.197426795959473, 6.185598850250244, 6.175104856491089, 6.180721044540405, 6.184389591217041]\n",
            "[07/05 08:22:37] __main__ INFO: Total time taken by GLISTER = 0.0698 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Average Time / Epoch: {np.mean(timing)} \\nTotal Epochs: {num_epochs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEw6yODiL_CJ",
        "outputId": "7bad471d-2632-4a0b-ca77-afb4872bbb40"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Time / Epoch: 8.379764111836751 \n",
            "Total Epochs: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "OiR1Rbi5CgrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbe4c85-dcc5-440a-c1e6-edc9ea953e35"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul  5 08:22:37 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    43W / 250W |   7409MiB / 16280MiB |     16%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9hnoIcO1L1iy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}